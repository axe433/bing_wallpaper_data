import requests
import json
import os
from datetime import datetime, timezone
import urllib.parse

print("Starts time: ", datetime.now(timezone.utc))
# å®šä¹‰å›½å®¶å’Œè¯­è¨€ä»£ç åˆ—è¡¨
country_to_lang = {
    'us': 'en-US',
    'gb': 'en-GB',
    'de': 'de-DE',
    'fr': 'fr-FR',
    'it': 'it-IT',
    'es': 'es-ES',
    'pt': 'pt-PT',
    'pl': 'pl-PL',
    'ua': 'uk-UA',
    'nl': 'nl-NL',
    'se': 'sv-SE',
    'fi': 'fi-FI',
    'no': 'nb-NO',
    'dk': 'da-DK',
    'cz': 'cs-CZ',
    'gr': 'el-GR',
    'ru': 'ru-RU',
    'ca': 'en-CA',
    'au': 'en-AU',
    'cn': 'zh-CN',
    'hk': 'zh-HK',
    'tw': 'zh-TW',
    'sg': 'en-SG',
    'jp': 'ja-JP',
    'kr': 'ko-KR',
    'in': 'hi-IN',
    'id': 'id-ID',
    'th': 'th-TH',
    'vn': 'vi-VN',
    'my': 'ms-MY',
    'br': 'pt-BR',
    'ar': 'es-AR',
    'tr': 'tr-TR',
    'za': 'af-ZA'
}

# ç¡®ä¿æ‰€æœ‰ç›®æ ‡æ–‡ä»¶å¤¹å­˜åœ¨
for country, lang in country_to_lang.items():
    directory = f'./jsonc/{country}'
    if not os.path.exists(directory):
        os.makedirs(directory)

#  date_field='enddate', unique_field='fullstartdate'
def merge_images(existing_images, new_images, date_field, unique_field=None):
    existing_dates = {image[date_field] for image in existing_images if date_field in image}
    if unique_field:
        # åˆ›å»ºä¸€ä¸ªé›†åˆæ¥å¿«é€ŸæŸ¥æ‰¾å·²å­˜åœ¨çš„å”¯ä¸€æ ‡è¯†
        existing_ids = {image[unique_field] for image in existing_images if unique_field in image}
    else:
        existing_ids = set()

    added_count = 0
    skipped_count = 0

    for image_info in new_images:
        # åªå¤„ç†åŒ…å« fullstartdate çš„æ•°æ®
        if unique_field and unique_field in image_info:
            #  TODO ä½¿ç”¨ fullstartdate å¯¹æ¯”
            unique_id = image_info[unique_field]
            if unique_id not in existing_ids:
                # å¦‚æœä¸å­˜åœ¨ï¼Œæ·»åŠ æ–°æ•°æ®
                existing_images.append(image_info)
                existing_ids.add(unique_id)
                added_count += 1
                print(f"  â• æ·»åŠ æ–°æ•°æ®: {unique_id}")
            else:
                # å¦‚æœå·²å­˜åœ¨ï¼Œå®Œå…¨è·³è¿‡ï¼Œä¿ç•™æ—§æ•°æ®ä¸å˜
                skipped_count += 1
                print(f"  â­ï¸  è·³è¿‡å·²å­˜åœ¨æ•°æ®: {unique_id}")
        # å¤„ç†ä¸åŒ…å« fullstartdate çš„æ•°æ®ï¼Œä»ç„¶ä½¿ç”¨ date è¿›è¡Œåˆ¤æ–­
        elif image_info[date_field] not in existing_dates:
            #  TODO ä½¿ç”¨ enddate è¿›è¡Œå¯¹æ¯”
            existing_images.append(image_info)
            existing_dates.add(image_info[date_field])
            added_count += 1
            print(f"  â• æ·»åŠ æ–°æ•°æ® (æŒ‰æ—¥æœŸ): {image_info[date_field]}")
        else:
            skipped_count += 1
            print(f"  â­ï¸  è·³è¿‡å·²å­˜åœ¨æ•°æ® (æŒ‰æ—¥æœŸ): {image_info[date_field]}")

    # æŒ‰æ—¥æœŸå€’åºæ’åº
    existing_images.sort(key=lambda x: datetime.strptime(x[date_field], '%Y%m%d'), reverse=True)

    print(f"  ğŸ“Š æ•°æ®ç»Ÿè®¡: æ–°å¢ {added_count} æ¡ï¼Œè·³è¿‡ {skipped_count} æ¡")
    return existing_images


# éå†æ¯ç§è¯­è¨€
for country, lang in country_to_lang.items():
    # å®šä¹‰API URLï¼Œä½¿ç”¨ä¸åŒçš„è¯­è¨€ä»£ç 
    api_url = f"https://www.bing.com/HPImageArchive.aspx?format=js&idx=0&n=8&mkt={lang}"
    api_description = f"https://www.bing.com/hp/api/model?toWww=1&mkt={lang}"
    # api_url = f"https://www.bing.com/HPImageArchive.aspx?format=js&idx=8&n=8&mkt={lang}" # old
    # è¯­è¨€ä¸æ”¯æŒï¼Œä¼šä½¿ç”¨é€šç”¨ ROW æ•°æ®
    if (lang == "hu-HU"): lang = "ROW"

    # å‘èµ·è¯·æ±‚è·å–æ•°æ®
    response = requests.get(api_url)
    response_description = requests.get(api_description)

    # Save the response data
    response_dir = f"response/{country}"
    os.makedirs(response_dir, exist_ok=True)

    # è·å–å½“å‰æ—¥æœŸå¹¶æ ¼å¼åŒ–
    current_date = datetime.now().strftime('%Y%m%d')

    with open(os.path.join(response_dir, f'{current_date}_data_image.json'), 'w', encoding='utf-8') as f:
        f.write(response.text)

    with open(os.path.join(response_dir, f'{current_date}_data_description.json'), 'w', encoding='utf-8') as f:
        f.write(response_description.text)
    
    data = response.json()
    data_description = response_description.json()

    # æå–æ‰€éœ€æ•°æ®å¹¶æ ¼å¼åŒ–
    images_info = []
    for image in data['images']:
        # image_info = {
        #     'startdate': datetime.strptime(image['startdate'], '%Y%m%d').strftime('%Y%m%d'),
        #     'fullstartdate': image['fullstartdate'],
        #     'enddate': datetime.strptime(image['enddate'], '%Y%m%d').strftime('%Y%m%d'),
        #     'url': image['url'],
        #     'urlbase': image['urlbase'],
        #     'copyright': image['copyright'],
        #     'copyrightlink': image['copyrightlink'],
        #     'title': image['title'],
        #     'quiz': image['quiz'],
        #     'hsh': image['hsh'],
        #     'drk': image['drk'],
        #     'top': image['top'],
        #     'bot': image['bot'],
        #     # 'tag': [name, id] # such as "tag": ["DugiOtokCroatia","EN-CA6561432536"]
        # }
        image_info = image
        images_info.append(image_info)
    
    for image2 in data_description['MediaContents']:
        fullstartdate = image2['Ssd'].replace('_', '')
        # description = image2['ImageContent']['Description']
        # æ‰¾åˆ°å¯¹åº” fullstartdate çš„ image_infoï¼Œå¹¶æ·»åŠ  description
        for image_info in images_info:
            if image_info['fullstartdate'] == fullstartdate or image_info['startdate'] == fullstartdate:
                image_info['MediaContent'] = image2
                break  # æ‰¾åˆ°åŒ¹é…é¡¹åè·³å‡ºå¾ªç¯


    # å®šä¹‰ä¸è¯­è¨€ä»£ç ç›¸å…³çš„æ–‡ä»¶è·¯å¾„
    file_path_current = f'./jsonc/{country}/bing.jsonc'

    # å‡½æ•°è¯»å†™æ•°æ®
    def read_json(file_path):
        try:
            with open(file_path, 'r', encoding='utf-8') as file:
                return json.load(file)
        except FileNotFoundError:
            return []

    def write_json(file_path, data):
        with open(file_path, 'w', encoding='utf-8') as file:
            json.dump(data, file, ensure_ascii=False, indent=4)

    # è¯»å–ç°æœ‰æ•°æ®
    existing_images_info_current = read_json(file_path_current)

    # è¿‡æ»¤å¹¶åˆå¹¶æ–°æ•°æ®
    existing_images_info_current = merge_images(existing_images_info_current, images_info, date_field='enddate', unique_field='fullstartdate')

    # å°†æ›´æ–°åçš„æ•°æ®å†™å›åˆ°æœ¬åœ°JSONæ–‡ä»¶
    write_json(file_path_current, existing_images_info_current)
    print(f"Bing Daily Image data has been saved to '{file_path_current}'")

print("Bing Image of the Day data is saved for all languages.")
print("Ends time: ", datetime.now(timezone.utc))
